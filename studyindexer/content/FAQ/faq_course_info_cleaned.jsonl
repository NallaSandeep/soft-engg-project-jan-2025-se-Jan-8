{"topic": "Course Information", "question": "What is the course structure and content of 'Foundational Level Courses'?", "answer": "Foundational Level Courses\n1.  **Statistics for Data Science I**\n    *   **Level of Course:** Foundational Level Course\n    *   **Name of course:** Statistics for Data Science I\n    *   **Professor:** Usha Mohan\n    *   **Course ID:** BSMA1002\n    *   **Course Credits:** 4\n    *   **Course Type:** Foundational\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Create, download, manipulate, and analyse data sets. Frame questions that can be answered from data in terms of variables and cases. Describe data using numerical summaries and visual representations. Estimate chance by applying laws of probability. Translate real-world problems into probability models. Calculating expectation and variance of a random variable. Describe and apply the properties of the Binomial Distribution and Normal distribution.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction and type of data, Types of data, Descriptive and Inferential statistics, Scales of measurement\n        *   WEEK 2: Describing categorical data Frequency distribution of categorical data, Best practices for graphing categorical data, Mode and median for categorical variable\n        *   WEEK 3: Describing numerical data Frequency tables for numerical data, Measures of central tendency - Mean, median and mode, Quartiles and percentiles, Measures of dispersion - Range, variance, standard deviation and IQR, Five number summary\n        *   WEEK 4: Association between two variables - Association between two categorical variables - Using relative frequencies in contingency tables, Association between two numerical variables - Scatterplot, covariance, Pearson correlation coefficient, Point bi-serial correlation coefficient\n        *   WEEK 5: Basic principles of counting and factorial concepts - Addition rule of counting, Multiplication rule of counting, Factorials\n        *   WEEK 6: Permutations and combinations\n        *   WEEK 7: Probability Basic definitions of probability, Events, Properties of probability\n        *   WEEK 8: Conditional probability - Multiplication rule, Independence, Law of total probability, Bayes\u2019 theorem\n        *   WEEK 9: Random Variables - Random experiment, sample space and random variable, Discrete and continuous random variable, Probability mass function, Cumulative density function\n        *   WEEK 10: Expectation and Variance - Expectation of a discrete random variable, Variance and standard deviation of a discrete random variable\n        *   WEEK 11: Binomial and poisson random variables - Bernoulli trials, Independent and identically distributed random variable, Binomial random variable, Expectation and variance of abinomial random variable, Poisson distribution\n        *   WEEK 12: Introduction to continous random variables - Area under the curve, Properties of pdf, Uniform distribution, Exponential distribution\n    *   **About the Instructors:** Usha Mohan holds a Ph.D. from Indian Statistical Institute. She has worked as a researcher in ISB Hyderabad and Lecturer at University of Hyderabad prior to joining IIT Madras. She offers courses in Data analytics, Operations research, and Supply chain management to under graduate, post graduate and doctoral students. In addition, she conducts training in Optimization methods and Data Analytics for industry professionals. Her research interests include developing quantitative models in operations management and combinatorial optimization.\n\n2.  **Introduction to Programming**\n    *   **Level of Course:** Foundational Level Course (based on context)\n    *   **Name of course:** Introduction to Programming\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** BSCS1001\n    *   **Course Credits:** 4\n    *   **Course Type:** Foundational\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Applying a procedural approach to real life problems: sequencing basic steps, identifying common patterns. Communicating procedural descriptions: flowcharts, pseudo-code. Understanding underlying abstractions used in programming, through examples: variables, iteration, accumulation, filtering, parametrised procedures, polymorphism and state. Selecting appropriate data structures to store relationships between data: lists, trees, matrices, graphs. Identifying algorithmic techniques to solve a given problem: searching, sorting, indexing, matching. Decomposing problems into smaller units to find a solution: recursion, divide and conquer. Understanding and checking algorithms: predict their behaviour, design tests to verify their output, perform simple debugging.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Variables, Initialization, Iterators, Filtering, Datatypes, Flowcharts, Sanity of data\n        *   WEEK 2: Iteration, Filtering, Selection, Pseudocode, Finding max and min, AND operator\n        *   WEEK 3: Multiple iterations (non-nested), Three prizes problem, Procedures, Parameters, Side effects, OR operator\n        *   WEEK 4: Nested iterations, Birthday paradox, Binning\n        *   WEEK 5: List, Insertion sort\n        *   WEEK 6: Table, Dictionar\n        *   WEEK 7: Graph, Matrix\n        *   WEEK 8: Adjacency matrix, Edge labelled graph\n        *   WEEK 9: Backtracking, Tree, Depth First Search (DFS), Recursion\n        *   WEEK 10: Object oriented programming, Class, Object, Encapsulation, Abstraction, Information hiding, Access specifiers\n        *   WEEK 11: Message passing, Remote Procedure Call (RPC), Cache memory, Parallelism, Concurrency, Polling, Preemption, Multithreading, Producer Consumer, Atomicity, Consistency, Race condition, Deadlock, Broadcasting\n        *   WEEK 12: Top-down approach, Bottom-up approach, Decision tree, Numerical prediction, Behaviour analysis, Classification\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n3.  **Introduction to Python Programming**\n    *   **Level of Course:** Foundational Level Course (based on context)\n    *   **Name of course:** Introduction to Python Programming (inferred from content)\n    *   **Professor:** Sudarshan Iyengar\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** Programming (based on context)\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to algorithms\n        *   WEEK 2: Conditionals\n        *   WEEK 3: Conditionals (Continued)\n        *   WEEK 4: Iterations and Ranges\n        *   WEEK 5: Iterations and Ranges (Continued)\n        *   WEEK 6: Basic Collections in Python\n        *   WEEK 7: Basic Collections in Python (Continued)\n        *   WEEK 8: Basic Collections in Python (Continued)\n        *   WEEK 9: File Operations\n        *   WEEK 10: File Operations (Continued)\n        *   WEEK 11: Module system in python\n        *   WEEK 12: Basic Pandas and Numpy processing of data\n    *   **About the Instructors:** Sudarshan Iyengar has a PhD from the Indian Institute of Science and is currently working as an Associate Professor and Head of CSE at IIT Ropar.\n\n4.  **English I**\n    *   **Level of Course:** Foundational Level Course\n    *   **Name of course:** English I\n    *   **Professor:** Rajesh Kumar, Karthika Sathyanathan\n    *   **Course ID:** BSHS1001\n    *   **Course Credits:** 4\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** This course aims at achieving fluency and confidence in spoken and written English. This course will use insights from theories of learning and dominant methods of teaching language.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Sounds and Words (Vowel and Consonant sounds)\n        *   WEEK 2: Parts of Speech\n        *   WEEK 3: Sentences (Phrases and Idioms)\n        *   WEEK 4: Speaking Skills (Spoken English Preliminaries)\n        *   WEEK 5: Tenses and Agreement in English Sentences\n        *   WEEK 6: Reading Skills (Skimming, Scanning and Comprehension)\n        *   WEEK 7: Listening Skills\n        *   WEEK 8: Aspiration, Word Stress and Syllabification\n        *   WEEK 9: Speaking Skills (Presentation and Group Discussion)\n        *   WEEK 10: Grammar (Common Errors in English) and Writing Skills\n        *   WEEK 11: Writing Skills (Basics of Writing)\n        *   WEEK 12: Writing Skills (Professional Writing)\n    *   **About the Instructors:** Rajesh Kumar is a Professor in the Department of Humanities and Social Sciences at IIT Madras. (Information about Karthika Sathyanathan is not provided in this excerpt).\n\n5.  **English II**\n    *   **Level of Course:** Foundational Level Course (based on context)\n    *   **Name of course:** English II (inferred from context, BSHS1002 mentioned as 'Other courses by the same instructor')\n    *   **Professor:** Rajesh Kumar\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** 4\n    *   **Course Type:** Foundational\n    *   **Pre-requisites:** BSHS1001 - English I\n    *   **What you\u2019ll learn:** Integrating the basic skills of language into developing advanced skills of language proficiency to help compose clear and detailed writing on a range of subjects. Learning advanced level of vocabulary and socio-linguistic/ socio-pragmatic competence for advance reading and writing. Building nuanced structure for grammatical accuracy for fluency and creating confidence and appropriateness for expressing view-points clearly. Developing elementary foundations for comprehending and conveying underlying meaning in spoken discourse.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Patterns in Sentences\n        *   WEEK 2: Patterns in Sentences (Continued)\n        *   WEEK 3: Patterns in Sentences (Continued)\n        *   WEEK 4: Listening Skills\n        *   WEEK 5: Listening Skills (Continued)\n        *   WEEK 6: Speaking Skills\n        *   WEEK 7: Speaking Skills (Continued)\n        *   WEEK 8: Reading Skills\n        *   WEEK 9: Writing Skills\n        *   WEEK 10: Writing Skills (Continued)\n        *   WEEK 11: Social Skills\n        *   WEEK 12: Social Skills (Continued)\n    *   **About the Instructors:** Rajesh Kumar is a Professor in the Department of Humanities and Social Sciences at IIT Madras (mentioned in the English I course).\n\n6.  **Mathematics for Data Science I**\n    *   **Level of Course:** Foundational Level Course\n    *   **Name of course:** Mathematics for Data Science I\n    *   **Professor:** Neelesh Upadhye, Madhavan Mukund\n    *   **Course ID:** BSMA1001\n    *   **Course Credits:** 4\n    *   **Course Type:** Foundational\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Recall the basics of sets, natural numbers, integers, rational numbers, and real numbers. Learn to use the coordinate system, and plot straight lines. Identify the properties and differences between linear, quadratic, polynomial, exponential, and logarithmic functions. Find roots, maxima and minima of polynomials using algorithmic methods. Learn to represent sets and relations between set elements as discrete graphs using nodes and edges. Formulate some common real-life problems on graphs and solve them.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Set Theory - Number system, Sets and their operations, Relations and functions - Relations and their types, Functions and their types\n        *   WEEK 2: Rectangular coordinate system, Straight Lines - Slope of a line, Parallel and perpendicular lines, Representations of a Line, General equations of a line, Straight-line fit\n        *   WEEK 3: Quadratic Functions - Quadratic functions, Minima, maxima, vertex, and slope, Quadratic Equations\n        *   WEEK 4: Algebra of Polynomials - Addition, subtraction, multiplication, and division, Algorithms, Graphs of Polynomials - X-intercepts, multiplicities, end behavior, and turning points, Graphing & polynomial creation\n        *   WEEK 5: Functions - Horizontal and vertical line tests, Exponential functions, Composite functions, Inverse functions\n        *   WEEK 6: Logarithmic Functions - Properties, Graphs, Exponential equations, Logarithmic equations\n        *   WEEK 7: Sequence and Limits - Function of One variable - \u2022 Function of one variable \u2022 Graphs and Tangents \u2022 Limits for sequences \u2022 Limits for function of one variable \u2022 Limits and Continuity\n        *   WEEK 8: Derivatives, Tangents and Critical points - \u2022 Differentiability and the derivative \u2022 Computing derivatives and L\u2019H\u02c6opital\u2019s rule \u2022 Derivatives, tangents and linear approximation \u2022 Critical points: local maxima and minima\n        *   WEEK 9: Integral of a function of one variable - \u2022 Computing areas, Computing areas under a curve, The integral of a function of one variable \u2022 Derivatives and integrals for functions of one variable\n        *   WEEK 10: Graph Theory - Representation of graphs, Breadth-first search, Depth-first search, Applications of BFS and DFS; Directed Acyclic Graphs - Complexity of BFS and DFS, Topological sorting\n        *   WEEK 11: Longest path, Transitive closure, Matrix multiplication Graph theory Algorithms - Single-source shortest paths, Dijkstra's algorithm, Bellman-Ford algorithm, All-pairs shortest paths, Floyd\u2013Warshall algorithm, Minimum cost spanning trees, Prim's algorithm, Kruskal's algorithm\n        *   WEEK 12: Revision\n    *   **About the Instructors:** Neelesh Upadhye is an experienced Associate Professor in the Department of Mathematics, IIT Madras. Madhavan Mukund's information is not provided in this excerpt.\n\n7.  **Mathematics for Data Science II**\n    *   **Level of Course:** Foundational Level Course\n    *   **Name of course:** Mathematics for Data Science II\n    *   **Professor:** Sarang S Sane\n    *   **Course ID:** BSMA1003\n    *   **Course Credits:** 4\n    *   **Course Type:** Foundational\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** This course aims to introduce the basic concepts of linear algebra, calculus and optimization with a focus towards the application area of machine learning and data science.\n    *   **Course structure & Assessments:** 11 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 11\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Vector and matrices - Vectors; Matrices; Systems of Linear Equations; Determinants (part 1); Determinants (part 2)\n        *   WEEK 2: Solving linear equations - Determinants (part 3); Cramer's Rule; \"Solutions to a system of linear equations with an invertible coefficient matrix\"; The echelon form; Row reduction; The Gaussian elimination method\n        *   WEEK 3: Introduction to vector spaces - Introduction to vector spaces; Some properties of vector spaces; Linear dependence; Linear independence - Part ; Linear independence - Part 2\n        *   WEEK 4: Basis and dimension - What is a basis for a vector space?; Finding bases for vector spaces; What is the rank/dimension for a vector space; Rank and dimension using Gaussian elimination\n        *   WEEK 5: Rank and Nullity of a matrix; Introduction to Linear transformation - The null space of a matrix : finding nullity and a basis - Part 1; The null space of a matrix : finding nullity and a basis - Part 2; What is a linear mapping - Part 1; What is a linear mapping - Part 2; What is a linear transformation\n        *   WEEK 6: Linear transformation, Kernel and Images - Linear transformations, ordered bases and matrices; Image and kernel of linear transformations; Examples of finding bases for the kernel and image of a linear transformation\n        *   WEEK 7: Equivalent and Similar matrices; Introduction to inner products - Equivalence and similarity of matrices; Affine subspaces and affine mappings; Lengths and angles; Inner products and norms on a vector space\n        *   WEEK 8: Orthogonality, Orthonormality; Gram-schmidt method - Orthgonality and linear independence; What is an orthonormal basis? Projections using inner products; The Gram-Schmidt process; Orthogonal transformations and rotations\n        *   WEEK 9: Multivariable functions, Partial derivatives, Limit, continuity and directional derivatives - Multivariable functions : visualization; Partial derivatives; Directional derivatives; Limits for scalar-valued multivariable functions; Continuity for multivariable functions; Directional derivatives in terms of the gradient\n        *   WEEK 10: Directional ascent and descent, Tangent (hyper) plane, Critical points - The directional of steepest ascent/descent; Tangents for scalar-valued multivariable functions; Finding the tangent hyper(plane); Critical points for multivariable functions\n        *   WEEK 11: Higher order partial derivatives, Hessian Matrix and local extrema, Differentiability - Higher order partial derivatives and the Hessian matrix; The Hessian matrix and local extrema for f(x,y); The Hessian matrix and local extrema for f(x,y,z); Differentiability for Multivariable Functions; Review of Maths - 2\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)", "tags": ["foundational", "level", "courses"], "source": "IITM BS Website"}
{"topic": "Course Information", "question": "What is the course structure and content of 'Diploma Level Courses'?", "answer": "Diploma Level Courses\n\n1.  **Business Data Management**\n    *   **Level of Course:** Diploma Level Course\n    *   **Name of course:** Business Data Management\n    *   **Professor:** Dr. G Venkatesh, Prof. Suresh Babu, Dr. Milind Gandhe\n    *   **Course ID:** BSMS2001\n    *   **Course Credits:** 4\n    *   **Course Type:** Data Science\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Understand the business context: consumption patterns, micro-economic concepts underlying demand and supply. Analyse firm-level and industry-level data. Discover how businesses operate, and how they are actively managed using data dashboards. Get a handle on the data that originates from business processes. Identify the techniques used to represent and structure this data. Gain skills on the use of worksheets to organise, interpret and present data. Working with large data sets.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Consumption and demand: Micro & Macro economics: the role of data, production, consumption and exchange, consumption baskets, sources of consumer survey data\n        *   WEEK 2: Micro-economic concepts: Utility: cardinal vs ordinal, indifference curves. Demand and supply curves, changes in demand and elasticity. production cost, cost curves. Make vs buy decisions, production quantity decisions\n        *   WEEK 3: Firm level strategies and performance data: Objectives and types of pricing strategies, analysis of firm performance - key ratios. Analysis examples: Ultratech, Page Industries, Nestle, TCS\n        *   WEEK 4: Analysing industry level data: Industry definition and classification codes, IIP and PMI, industry market structure and concentration indices, competitive positioning in an industry - Porter's five forces. Analysis examples: Cement industry, Textile industry, FMCG industry, IT industry\n        *   WEEK 5: Case study 1 - Fabmart (E-Commerce): Introduction to E-Commerce, Fabmart case introduction, explanation of data set & questions to be answered, revenue pareto, volume pareto, scatter plot of sales and revenue, revenue trend\n        *   WEEK 6: Fabmart case continued: Sales analysis, organisation of distribution centre, analysis of sales trends, average days of inventory, ledger, avoiding stockouts\n        *   WEEK 7: Case study 2 - Ace Gears (Manufacturing): Introduction to the manufacturing sector, context of the automotive industry during the years 2019-2021, explanation of data set containing monthly information on sales, production, inventory and costing. Revenue trend analysis, portfolio management\n        *   WEEK 8: Ace Gears case study continued: Regional sales analysis, sales agent planning, production scheduling, scrap analysis, unit level profitability analysis, raw material re-ordering and safety stock\n        *   WEEK 9: Case study 3 - Tech Enterprises (IT): Introduction to HR as a function, Introduction to the Tech Enterprises, internal sourcing, ranking of internal candidates, job description, sourcing channels and their analysis, recruitment process and onboarding\n        *   WEEK 10: Case study 4 - PayBuddy (Fin Tech): Introduction to Finance Industry and Fintech, payment processing and money flow, new credit product introduction, nudge economics, payment transaction and customer data set, identifying rules to target the appropriate customers\n        *   WEEK 11: Paybuddy case continued: Introduction to A/B testing, analysis of the A/B testing data, credit risk evaluation, risk-return tradeoffs\n        *   WEEK 12: Discussion on student acquired data sets. Wrap upaWrap up (summary) of the case studies, course project work\n    *   **About the Instructors:** (Biographical information for Dr. G Venkatesh, Prof. Suresh Babu, and Dr. Milind Gandhe is not provided in this excerpt).\n\n2.  **Tools in Data Science**\n    *   **Level of Course:** Diploma Level Course\n    *   **Name of course:** Tools in Data Science\n    *   **Professor:** S Anand\n    *   **Course ID:** BSSE2002\n    *   **Course Credits:** 3\n    *   **Course Type:** Data Science\n    *   **Pre-requisites:** Python, HTML, JavaScript, Excel, data science basics\n    *   **What you\u2019ll learn:** This practical course will teach students to use popular tools for sourcing data, transforming it, analyzing it, communicating these as visual stories, and deploying them in production.\n    *   **Course structure & Assessments:** 9 modules over 12 weeks of coursework, online assignments for each module, 1 remote online exam, 2 take home projects, 1 in-person end term exam.\n    *   **Number of weeks:** 12 (coursework duration)\n    *   **(LIST)Week#, Title:**\n        *   MODULE 1: Everyday tools\n        *   MODULE 2: Data sourcing\n        *   MODULE 3: Data preparation\n        *   MODULE 4: Data analysis\n        *   MODULE 5: Large language models\n        *   MODULE 6: Geospatial and network analysis\n        *   MODULE 7: Data visualization\n        *   MODULE 8: Data storytelling\n        *   MODULE 9: Deployment\n    *   **About the Instructors:** (Biographical information for S Anand is not provided in this excerpt).\n\n3.  **Database Management Systems**\n    *   **Level of Course:** Diploma Level Course\n    *   **Name of course:** Database Management Systems\n    *   **Professor:** Prof. Partha Pratim Das\n    *   **Course ID:** BSCS2001\n    *   **Course Credits:** 4\n    *   **Course Type:** Programming\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** A comprehensive introduction to databases, database management, and relevant topics like database security, integrity, concurrency, and data warehousing.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Course Overview\n        *   WEEK 2: Relational Model and Basic SQL\n        *   WEEK 3: Intermediate and Advanced SQL\n        *   WEEK 4: Relational Query Languages and Database Design\n        *   WEEK 5: Functional Dependency and Normal Forms\n        *   WEEK 6: Functional Dependency and Normal Forms (cont.)\n        *   WEEK 7: Application Development\n        *   WEEK 8: Storage Management\n        *   WEEK 9: Indexing and Hashing\n        *   WEEK 10: Transactions\n        *   WEEK 11: Backup and Recovery\n        *   WEEK 12: Query Optimization and Conclusion\n    *   **About the Instructors:** Prof. Partha Pratim Das is a Professor in Computer Science and Engineering at IIT Kharagpur. He obtained his B Tech, M Tech and Ph D degrees from IIT Kharagpur. He served as a faculty member there from 1988 to 1998, moved to industry, and rejoined IIT Kharagpur in 2011. He is the Joint PI of the National Digital Library of India project and leads the national initiative to integrate digital learning contents.\n\n4.  **Machine Learning Techniques**\n    *   **Level of Course:** Diploma Level Course\n    *   **Name of course:** Machine Learning Techniques\n    *   **Professor:** Arun Rajkumar\n    *   **Course ID:** BSCS2007\n    *   **Course Credits:** 4\n    *   **Course Type:** Data Science\n    *   **Pre-requisites:** None\n    *   **Co-requisites:** BSCS2004 - Machine Learning Foundations\n    *   **What you\u2019ll learn:** Demonstrating In depth understanding of machine learning algorithms - model, objective or loss function, optimization algorithm and evaluation criteria. Tweaking machine learning algorithms based on the outcome of experiments - what steps to take in case of underfitting and overfitting. Being able to choose among multiple algorithms for a given task. Developing an understanding of unsupervised learning techniques.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction; Unsupervised Learning - Representation learning - PCA\n        *   WEEK 2: Unsupervised Learning - Representation learning - Kernel PCA\n        *   WEEK 3: Unsupervised Learning - Clustering - K-means/Kernel K-means\n        *   WEEK 4: Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm\n        *   WEEK 5: Supervised Learning - Regression - Least Squares; Bayesian view\n        *   WEEK 6: Supervised Learning - Regression - Ridge/LASSO\n        *   WEEK 7: Supervised Learning - Classification - K-NN, Decision tree\n        *   WEEK 8: Supervised Learning - Classification - Generative Models - Naive Bayes\n        *   WEEK 9: Discriminative Models - Perceptron; Logistic Regression\n        *   WEEK 10: Support Vector Machines\n        *   WEEK 11: Ensemble methods - Bagging and Boosting (Adaboost)\n        *   WEEK 12: Artificial Neural networks: Multiclass classification\n    *   **About the Instructors:** Arun Rajkumar is an Assistant Professor in the Department of Data Science and AI at IIT Madras. He was a research scientist at Xerox Research Center (now Conduent Labs) Bangalore for three years and earned his Ph.D from the Indian Institute of Science. His research interests are in Machine learning, statistical learning theory with applications to education and healthcare.\n\n5.  **Modern Application Development II**\n    *   **Level of Course:** Diploma Level Course (based on context, BSCS2006 mentioned as 'Other courses by the same instructor')\n    *   **Name of course:** Modern Application Development II (inferred from context)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** (Not explicitly stated in this excerpt)\n    *   **Co-requisites:** (Not explicitly stated in this excerpt)\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Basics of JavaScript\n        *   WEEK 2: Advanced JavaScript\n        *   WEEK 3: Introduction to Web Frontend\n        *   WEEK 4: Introduction to VueJS\n        *   WEEK 5: Vue with APIs\n        *   WEEK 6: Advanced Vuejs\n        *   WEEK 7: Advanced State Management\n        *   WEEK 8: Authentication and Designing APIs\n        *   WEEK 9: Asynchronous Jobs\n        *   WEEK 10: Inter-Service Messaging and Webhooks\n        *   WEEK 11: Performance\n        *   WEEK 12: Project\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n6.  **Modern Application Development I**\n    *   **Level of Course:** Diploma Level Course (based on context, BSCS2003 mentioned as 'Other courses by the same instructor')\n    *   **Name of course:** Modern Application Development I\n    *   **Professor:** Thejesh G N, Prof. Nitin Chandrachoodan\n    *   **Course ID:** BSCS2003\n    *   **Course Credits:** 4\n    *   **Course Type:** Programming\n    *   **Pre-requisites:** None\n    *   **Co-requisites:** BSCS2001 - Database Management Systems\n    *   **What you\u2019ll learn:** To be able to design a web application. To be able to distinguish between the frontend, the backend, and the database activities. To create such an application with Python and MySQL.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Basic terminologies of Web\n        *   WEEK 2: Webpages written in HTML and CSS\n        *   WEEK 3: Presentation layer - View\n        *   WEEK 4: Models - Introduction to databases\n        *   WEEK 5: Controllers - Business logic\n        *   WEEK 6: APIs and REST APIs\n        *   WEEK 7: Backend Systems\n        *   WEEK 8: Application Frontend\n        *   WEEK 9: Application Security\n        *   WEEK 10: Testing of Web Applications\n        *   WEEK 11: HTML Evolution and Beyond HTML\n        *   WEEK 12: Application Deployment\n    *   **About the Instructors:** Thejesh G N is a Software Consultant at IITM BSc Degree, IIT Madras. (Biographical information for Prof. Nitin Chandrachoodan is available in other course descriptions, but not repeated here for brevity).\n\n7.  **System Commands**\n    *   **Level of Course:** Diploma Level Course\n    *   **Name of course:** System Commands\n    *   **Professor:** Prof. Gandham Phanikumar\n    *   **Course ID:** BSSE2001\n    *   **Course Credits:** 3\n    *   **Course Type:** Programming\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 8 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 8\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to GNU/Linux OS. Setting up and running Linux environment. The command line environment. Knowing hardware of your machine Information - commands such as hwinfo, lshw, df, free etc. Diagnostics - commands to fetch hardware information such as battery state, memory modules etc., Knowing the OS and software of your machine Commands to get details about operating system, versions etc. Packages - installed / available Input / output redirection.\n        *   WEEK 2: Introduction to packages and repositories. Using 'apt' commands to manage packages. File types and related commands. Understanding file permissions and access modes. Managing file permissions through symbolic and numeric mode. Concept of environment variables. Important environment variables such as $HOME, $USER and $PATH\n        *   WEEK 3: Managing shell variables. Prompt strings. Symbolic links and hard links, brief introduction to inode numbers. Exploring the root file system and related commands. Using shell shortcuts with commands. Slicing output. Managing programs currently running on the machine. Shell access to a local / remote machine.\n        *   WEEK 4: Redirection to script, variable and for logging purpose. Using pipes. Introduction to regex; using regex patterns and egrep. Using egrep to extract useful information from files. find command and its uses - patterns to pick specific files in a folder, using exec Command line editors (nano, vi, emacs - syntax highlighting & prompting, configuring options) Writing and running simple Bash scripts.\n        *   WEEK 5: How are shell scripts interpreted? Using variables in scripts. Passing command line arguments to scripts, to create your own commands. More shell programming. Writing conditional statements using if /else / fi. Introduction to loops. Using functions Configuring startup / periodic / recurring tasks\n        *   WEEK 6: Text processing using AWK language. Using awk to run statics on a data file. Using regex within awk. Awk as a programming language Introduction to 'sed' \u2013 another text processing utility. Line by line processing to replace a regex pattern with a string. Use of place holders for matching regex patterns for use in replacing strings.\n        *   WEEK 7: Introduction to make utility; concept of target and dependency; actions performed by make; conditional compilation; passing shell variables to make; File packaging utilities such as compress, tar, zip, gzip, bzip2, xz. Networking concepts Introduction to IP addresses. Concept of localhost. Intranet and public addresses. Concept of ports and services that run on these ports. Concept of DNS and Domain names. Network diagnostics using tools and commands. Scripting a tool for analysis of logs.\n        *   WEEK 8: Introduction to RAID for handling hardware failure. Introduction to version control Git as a version control system: Overview of Git workflow Branches, repositories, forks, etc. Creating and merging pull requests. Personal access tokens. Managing changes as local and remote. Working demo of a public repository using Git Approval workflow How a team collaborates on the private repository in an organization. Managing pull requests for the owner, raising issues and resolving them.\n    *   **About the Instructors:** (Biographical information for Prof. Gandham Phanikumar is not provided in this excerpt).", "tags": ["diploma", "level", "courses"], "source": "IITM BS Website"}
{"topic": "Course Information", "question": "What is the course structure and content of 'Degree Level Courses'?", "answer": "Degree Level Courses\n\n1.  **(Course Name Not Explicitly Stated - Discrete Mathematics)**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** (Discrete Mathematics - inferred from content)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 8 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 8\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: triangular numbers, Sigma Notation for Summation, Sequences, Peano's axioms for the natural numbers, Set Theory: the language of Mathematics, Hilbert Hotel, Bijections and Cardinality, The Natural Numbers, The Integers\n        *   WEEK 2: A Trip to Cantorsville, Cantor's Diagonalization Argument, Towards the Real Numbers, Ordered Field, Completeness Axiom, The Least Upper Bound Property, Mathematical Logic and Statements\n        *   WEEK 3: Currency Game, Divisibility, Greatest Common Divisor, The Euclidean Algorithm, Proof of the Euclidean Algorithm, Test for Divisibility\n        *   WEEK 4: Fermat's Little Theorem, Fundamental Theorem of Arithmetic, Modular Arithmetic, Arithmetic with Congruences, Infinitude of Primes, Inclusion\u2013Exclusion Principle\n        *   WEEK 5: Proof of Inclusion-Exclusion Principle, Pigeonhole Principle, Sieve of Eratosthenes, More on the Infinitude of Primes, Gaps Between Primes\n        *   WEEK 6: Binomial Coefficients, Binomial Theorem, Lattice Paths, Random Sampling, Permutations, Example of Inclusion-Exclusion Principle\n        *   WEEK 7: Graph Theory - Introduction, Connectedness and Distance in Graphs, Adjacency Matrix, Graph Trees, Sperners Lemma, Graph Coloring\n        *   WEEK 8: Limit of a Sequence, Properties of Limits, Sequential Continuity, Continuity of Trigonometric functions, Intermediate Value Theorem\n        *   WEEK 9: Limit of Fibonacci series, Lam\u00e9 formula, Sandwich Lemma, Shifting Lemma\n        *   WEEK 10: Derivatives, Fa\u00e0 di Bruno's formula\n        *   WEEK 11: Riemann Integrals, Mean Value Theorem\n        *   WEEK 12: Uniform continuity, Fundamental theorem of calculus\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n2.  **Privacy & Security in Online Social Media**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Privacy & Security in Online Social Media\n    *   **Professor:** Prof. Ponnurangam Kumaraguru\n    *   **Course ID:** BSCS3007\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** List various privacy and security concerns (spam, phishing, fraud nodes, identity theft) on online social networks. Describe different methodologies used for solving security and privacy problems on online social networks. Student will be able to collect data from OSM, analyze, and visualize the data within the context of Privacy & Security in Online Social Media. Design a project idea to attack one problem discussed in the course or any topic you identify in the online social networks (through Mini-Project)(Optional).\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Topics \u2013 Assessments Social network analysis 101 \u2013\n        *   WEEK 2: Collecting data from social media \u2013 Collect data, analyze, and report\n        *   WEEK 3: Text analysis of social media data \u2013 Analyze data and report\n        *   WEEK 4: Cyber crime on social media \u2013 Analyze data and report\n        *   WEEK 5: Cyber crime on social media \u2013 Reading paper and report\n        *   WEEK 6: Fake news on social media \u2013 Analyze data and report\n        *   WEEK 7: Fake news on social media \u2013 Reading paper and report\n        *   WEEK 8: Privacy on social media \u2013 Analyze data and report\n        *   WEEK 9: Privacy on social media \u2013 Reading paper and report\n        *   WEEK 10: Ethics, bias on online social media \u2013 Reading paper and report\n        *   WEEK 11: Computational social science \u2013 Reasoning / Comprehension of ideas\n        *   WEEK 12: Computational social science on online social media \u2013 Reading paper and report\n    *   **About the Instructors:** (Biographical information for Prof. Ponnurangam Kumaraguru is not provided in this excerpt).\n\n3.  **Big Data and Biological Networks**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Big Data and Biological Networks\n    *   **Professor:** Dr. Nirav P Bhatt, Karthik Raman, Prof. Himanshu Sinha\n    *   **Course ID:** BSBT4002\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** To enable the students to \u201cunderstand\u201d biological data, to represent, and analyze various datasets from a network perspective, to encourage network thinking applied to problems across disciplines, to understand various network models used to model real-world networks, to apply network analytics techniques to understand biological networks, to implement basic network analysis algorithms in Python, to learn different AI/ML problem formulations for biological data, and to apply AI/ML techniques for analysis of biological data using Python.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Biological Big Data. Information Flow in Biological Systems.\n        *   WEEK 2: Omics datasets: Various flavours of big biological datasets (genomic, transcriptomic, proteomic, metabolomic, etc.).\n        *   WEEK 3: Introduction to Graph theory. History. Types of graphs. Representing biological networks.\n        *   WEEK 4: Network structure: Key parameters, measures of centrality\n        *   WEEK 5: Key Network Models: Erdos-Renyi, Watts-Strogatz (small-world) and Barabasi-Albert (power-law models)\n        *   WEEK 6: Network clustering/community detection. Identifying motifs in networks. Studying network perturbations.\n        *   WEEK 7: Applications of network biology: Predicting drug targets, predicting drug molecules, synthesis of new molecules (chemoinformatics)\n        *   WEEK 8: Applications of network biology: Epidemiology, Centrality-lethality hypothesis.\n        *   WEEK 9: AI & ML for Biological Data Analysis. Introduction to AI & ML tasks in biological networks.\n        *   WEEK 10: Biological network reconstruction from omics and literature data\n        *   WEEK 11: Property prediction using network data. Node classification and link prediction.\n        *   WEEK 12: Analysis of heterogeneous and multi-layer/multiplex networks. Future Perspectives.\n    *   **About the Instructors:** (Biographical information for Dr. Nirav P Bhatt, Karthik Raman, and Prof. Himanshu Sinha is not provided in this excerpt).\n\n4.  **Market Research**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Market Research\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by \"basic understanding\")\n    *   **What you\u2019ll learn:** To provide a basic understanding of research methodology and its implementation in different business domains, to understand the role, scope, process, cost, and value of marketing research, to match research techniques to marketing problems, to analyse data and translate them into actionable findings, to enable students to do hands-on research to solve business problems.\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** (Not explicitly stated in this excerpt)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Marketing Research, the Research Process and Problem Formulation: The Role of Research in Marketing and the Marketing Research Process, Defining the Marketing Research Problem and Developing an Approach\n        *   WEEK 2: Research Design Formulation: Research Design, Exploratory Research Design, Descriptive Research Design, Causal Research Design and Test Markets\n        *   WEEK 3: Designing Data Collection Methods and Forms: Surveys and Interviews, Measurement, Measurement Scales, Questionnaires, and Instruments\n        *   WEEK 4: Different Market Research Applications, and the Industry Approach to each: Key marketing issues like new product development, STP, branding, etc. and the MR tools and techniques to address each\n        *   WEEK 5: Data Analysis and Interpretation: Entering the Data in SPSS, Examining the Data and Univariate Data Analysis: Descriptive Statistics, Cross Tabulation, Graphical Display of Data, Chart Deception and Hypothesis Testing: Mean Differences, ANOVA, Multivariate Data Analysis: An Overview, Exploratory Factor Analysis, Cluster Analysis, Multiple Regression in SPSS\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n5.  **(Course Name Not Explicitly Stated - Probability and Statistics II)**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** (Probability and Statistics II - inferred from content)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** (Not explicitly stated in this excerpt)\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Multiple random variables - Two random variables, Multiple random variables and distributions\n        *   WEEK 2: Multiple random variables - Independence, Functions of random variables - Visualization, functions of multiple random variables\n        *   WEEK 3: Expectations Casino math, Expected value of a random variable, Scatter plots and spread, Variance and standard deviation, Covariance and correlation, Inequalities\n        *   WEEK 4: Continuous random variables Discrete vs continuous, Weight data, Density functions, Expectations\n        *   WEEK 5: Multiple continuous random variables - Height and weight data, Two continuous random variables, Averages of random variables - Colab illustration, Limit theorems, IPL data - histograms and approximate distributions, Jointly Gaussian random variables Probability models for data - Simple models, Models based on other distributions, Models with multiple random variables, dependency, Models for IPL powerplay, Models from data\n        *   WEEK 6: Refresher week\n        *   WEEK 7: Estimation and Inference I\n        *   WEEK 8: Estimation and Inference II\n        *   WEEK 9: Bayesian estimation\n        *   WEEK 10: Hypothesis testing I\n        *   WEEK 11: Hypothesis Testing II\n        *   WEEK 12: Revision week\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n6.  **(Course Name Not Explicitly Stated - Linear Statistical Models)**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** (Linear Statistical Models - inferred from content)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Review of Estimation, Hypothesis Testing\n        *   WEEK 2: Review of working with R-package\n        *   WEEK 3: Least square estimation, estimable linear functions\n        *   WEEK 4: Normal equations\n        *   WEEK 5: Best Linear Unbiased Estimates (BLUEs).\n        *   WEEK 6: Gauss-Markov Theorem.\n        *   WEEK 7: Degrees of freedom. Fundamental Theorems of Least Square.\n        *   WEEK 8: Testing of linear hypotheses.\n        *   WEEK 9: One-way and two-way classification models\n        *   WEEK 10: ANOVA and ANCOVA.\n        *   WEEK 11: Nested models. Multiple comparisons\n        *   WEEK 12: Introduction to random effect models.\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n7.  **Software Testing**\n    *   **Level of Course:** Degree Level Course (Core Option I)\n    *   **Name of course:** Software Testing\n    *   **Professor:** Meenakshi D'Souza\n    *   **Course ID:** BSCS3002\n    *   **Course Credits:** 4\n    *   **Course Type:** Core Option I\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Software Testing: Motivation, Software Development Life Cycle, Terminologies and Processes, Software Test Automation: JUnit as an example\n        *   WEEK 2: Basics of Graphs, Fundamental Graph Algorithms, Elementary Graph Algorithms, Structural Graph Coverage Criteria, Algorithms: Structural Graph Coverage Criteria\n        *   WEEK 3: Graph Coverage Criteria: Applied to Test Code, Data Flow in Graphs,, Data Flow Testing Example, Unit Testing Based on Graphs: Summary\n        *   WEEK 4: Software Design and Integration Testing, Design Integration Testing and Graph Coverage, Specification Testing and Graph Coverage, Graph Coverage and Finite State Machines (FSM), Testing Source Code: Classical Coverage Criteria\n        *   WEEK 5: Logic: Basics needed for Software Testing, Coverage Criteria, Logic Coverage Criteria: Making clauses determine predicate, Applied to test code\n        *   WEEK 6: Logic: Coverage Example, Coverage Specification, Coverage FSM, Coverage Summary, SMT - Solvers\n        *   WEEK 7: Symbolic Testing, Concolic Execution, Example and Summary Symbolic Execution\n        *   WEEK 8: Requirements, Functional Testing, ISP, ISP Example\n        *   WEEK 9: Regular Expense CFGs, Mutation Testing, Mutation Operators Source Code, Mutation Testing Vs Other Criteria, Mutation Testing For Integration And Tools\n        *   WEEK 10: Basic Object Oriented (OO) Integration Concepts, Mutation Operators OO Integration, Mutation Operators OO Integration, OO Faults, Coupling Criteria\n        *   WEEK 11: Web Apps Intro, Client Side Testing, Server Side Testing\n        *   WEEK 12: Regression Testing, Software Quality Metrics, Non Functional Testing, TDD,Course Summary\n    *   **About the Instructors:** (Biographical information for Meenakshi D'Souza is not provided in this excerpt).\n\n8.  **Algorithms for Data Science (ADS)**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Algorithms for Data Science (ADS)\n    *   **Professor:** Arun Rajkumar\n    *   **Course ID:** BSDA5003\n    *   **Course Credits:** 4\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** BSCS2007 - Machine Learning Techniques\n    *   **What you\u2019ll learn:** The aim of this second-level graduate course is to provide a broad overview and develop the tools and methods necessary for the large-scale problems that naturally arise in many data science-related application areas.\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses by the same instructor)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Foundations of Randomized Methods & Concentration Inequalities\n        *   WEEK 2: Randomized SVD \u2013 I: Basics & Sampling Techniques\n        *   WEEK 3: Randomized SVD \u2013 II: Applications to PCA & Dimensionality Reduction\n        *   WEEK 4: Graph-Based Learning \u2013 I: Spectral Graph Theory, Clustering, Community Detection\n        *   WEEK 5: Graph-Based Learning \u2013 II: Graph-Based Ranking\n        *   WEEK 6: Dimension Reduction with Johnson-Lindenstrauss Lemma\n        *   WEEK 7: Approximate Nearest Neighbors (ANN) \u2013 I: LSH & Similarity Search\n        *   WEEK 8: Approximate Nearest Neighbors (ANN) \u2013 II: MinHash, SimHash, Bloom Filters\n        *   WEEK 9: Randomized Methods for Regression\n        *   WEEK 10: Matrix Sketching for Machine Learning\n        *   WEEK 11: Streaming Algorithms \u2013 I: Count-Min Sketch, Heavy Hitters, Frequency Moments\n        *   WEEK 12: Streaming Algorithms \u2013 II: Reservoir Sampling, Graph Streams, Streaming PCA\n    *   **About the Instructors:** Arun Rajkumar is an Assistant Professor in the Department of Data Science and AI at IIT Madras. He was a research scientist at Xerox Research Center (now Conduent Labs) Bangalore for three years and earned his Ph.D from the Indian Institute of Science. His research interests are in the areas of Machine learning, statistical learning theory with applications to education and healthcare.\n\n9.  **Algorithms**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** Algorithms\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** 4\n    *   **Course Type:** Programming\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Evaluating asymptotic upper bounds for algorithms using big O notation. Using standard data structures such as lists, arrays, stacks, queues, heaps. Comparing algorithms for sorting and searching. Representing, manipulating and analysing graphs. Mastering algorithm design techniques such as divide and conquer and dynamic programming. Applying linear programming and network flows to model computational problems.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Python Refresher\n        *   WEEK 2: Complexity, Notations, Sorting and Searching Algorithms\n        *   WEEK 3: Arrays, Lists, Stacks, Queues, Hashing\n        *   WEEK 4: Graph Algorithms\n        *   WEEK 5: Graph Algorithms (Continued)\n        *   WEEK 6: Union-Find Data Structure, Priority Queue, Heap, Binary Search Tree\n        *   WEEK 7: Balanced Search Tree, Greedy Algorithms\n        *   WEEK 8: Divide and Conquer\n        *   WEEK 9: Dynamic Programming\n        *   WEEK 10: String or Pattern Matching Algorithms\n        *   WEEK 11: Network Flows, Linear Programming, Class of Algorithms\n        *   WEEK 12: Summary\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n10. **Machine Learning Foundations**\n    *   **Level of Course:** Degree Level Course (based on context, BSCS2004 Course ID)\n    *   **Name of course:** Machine Learning Foundations\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** BSCS2004\n    *   **Course Credits:** 4\n    *   **Course Type:** Data Science\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** Recognising if a particular problem can be viewed as a Machine Learning problem. Breaking down standard Machine Learning problems into more fundamental problems using tools from Calculus, Linear Algebra, Probability and Optimisation. Recognising relationships between equation solving, projection onto a subspace, and the supervised learning problem of linear least squares regression. Visualising eigenvalue/eigenvectors as a property of a matrix, and recognising its potential in practical unsupervised learning problems like dimensionality reduction and image compression. Using, identifying failure modes, programming and debugging simple gradient descent methods for solving unconstrained optimisation problems. Recognising the value of simple models like Gaussian mixture models for data, constructing algorithms for learning the parameters of such models, and interpreting these parameters.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to machine learning\n        *   WEEK 2: Calculus\n        *   WEEK 3: Linear Algebra - Least Squares Regression\n        *   WEEK 4: Linear Algebra - Eigenvalues and eigenvectors\n        *   WEEK 5: Linear Algebra - Symmetric matrices\n        *   WEEK 6: Linear Algebra - Singular value decomposition, Principal Component Analysis in Image Processing\n        *   WEEK 7: Unconstrained Optimisation\n        *   WEEK 8: Convex sets, functions, and optimisation problems\n        *   WEEK 9: Constrained Optimisation and Lagrange Multipliers. Logistic regression as an optimization problem\n        *   WEEK 10: Examples of probabilistic models in machine learning problems\n        *   WEEK 11: Exponential Family of distributions\n        *   WEEK 12: Parameter estimation. Expectation Maximization.\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n11. **Introduction to Natural Language Processing (i-NLP)**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Introduction to Natural Language Processing (i-NLP)\n    *   **Professor:** Parameswari Krishnamurthy, Rahul Mishra\n    *   **Course ID:** BSCS5002\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** BSCS3004 - Deep Learning\n    *   **What you\u2019ll learn:** Why is processing language computationally hard and why specialized techniques need to be developed to process texts?. Knowledge and in-depth understanding of linguistics techniques and classical (statistical) approaches (pre-deep learning era) to NLP and their limitations. Knowledge and in-depth understanding of deep learning approaches (RNN and CNN) to NLP. Knowledge and in-depth understanding of Attention Mechanism, Transformers and Large Language Models (LLMs). Ability to read and understand latest NLP-related research papers. Ability to identify applicable NLP technique to solve a real-world problem involving text processing. Ability to implement NLP models and algorithms for problems related to text processing. Ability to develop applications based on textual generative models (LLMs - Large Language Models).\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Natural Language (NL) Why is it hard to process a natural language? Levels of Language Processing, Linguistic Fundamentals for NLP\n        *   WEEK 2: Text Processing and Preprocessing: Tokenization, Normalization, Stop word removal, Stemming, lemmatization, Morphological Analysis & Finite State Transducers (Code demo: Tokenization, Stop-Word-Removel, Stemming, Lemmatization)\n        *   WEEK 3: Part-of-speech tagging and Named Entities; Sequence Models: Hidden-Markov Models, MEMM and CRF; Classification Models: Na\u00efve Bayes, Logistic Regression, Clustering. (Code demo: HMM, CRF, Naive Bayes, LR, KNN)\n        *   WEEK 4: Syntax and Parsing: Constituency parsing, Dependency parsing, Parsing algorithms; Meaning Representation: Logical Semantics, Semantic Role Labelling (Code demo: Transition-based Parser, Graph-based parser, SRL-CRF (Prop bank.))\n        *   WEEK 5: Distributional Semantics, n-gram and Word2Vec, GloVe; Discourse Processing: Anaphora and Coreference Resolution and Discourse Connectives. Machine Translation (Code demo: Word2Vec, Glove, openNMT)\n        *   WEEK 6: Recurrent neural networks, LSTMs/GRUs, Neural Sequence Models, Contextualized Word Embeddings: TagLM, ELMO, ULMFIT, etc., Attention Mechanism (Code demo: LSTM/GRU)\n        *   WEEK 7: Transformers, Self-attention Mechanism, Sub-word tokenization, Positional encoding, Pre-trained Language Models (PLMs): BERT, GPT, etc. Fine-tuning and transfer learning (Code demo: Transformers).\n        *   WEEK 8: Large Language Models (LLMs) Parameter Efficient Fine Tuning: Prefix-coding, LORA, QLORA, etc. Emergent Behavior: In-context learning, Instruction Fine Tuning, RLHF, DPO (Code demo: LLMs with Hugging face)\n        *   WEEK 9: Natural Language Generation, Decoding schemes: greedy, Random sampling, Top-k, Top-p, Speculative sampling, etc.\n        *   WEEK 10: NLP applications: QnA, Summarization, NLI, Fact-checking, etc. Retrieval Augmented generation (RAG). (Code demo: Summarisation)\n        *   WEEK 11: Model Explainability: Attention maps, Attention-flow/rollout, Integrated gradients, etc. (Code demo: Attension visualization and Integrated gradients )\n        *   WEEK 12: Ethical and cultural considerations and biases.\n    *   **About the Instructors:** Parameswari Krishnamurthy is an Assistant Professor at the Language Technologies Research Center (LTRC), IIIT Hyderabad. (Biographical information for Rahul Mishra is not provided in this excerpt).\n\n12. **Introduction to Big Data**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Introduction to Big Data\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by \"basic introduction\")\n    *   **What you\u2019ll learn:** This course will introduce students to practical aspects of analytics at a large scale, i.e. big data. The course will start with a basic introduction to big data and cloud concepts spanning hardware, systems and software, and then delve into the details of algorithm design and execution at large scale.\n    *   **Course structure & Assessments:** 11 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 11\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction: Big data concepts & GCP Platform Setup\n        *   WEEK 2: Cloud concepts: Cloud-Native architecture, serverless computing, message queues, PaaS, SaaS, IaaS\n        *   WEEK 3: Types of Data: Data formats, sources & their semantics, processing & storage options on Cloud. Use of serverless to get started (e.g. Google Cloud Functions)\n        *   WEEK 4: Intro to Big Data Engineering: Hadoop and PySpark\n        *   WEEK 5: ELT: ETL, processing patterns for large data, ETL vs ELT, role of a scheduler\n        *   WEEK 6: SQL & NoSQL: For most analysis tasks, SQL is sufficient. Tools like Spark SQL allow that familiarity to translate to big data solutions. Types of NoSQL, evolution, best-of-fit options.\n        *   WEEK 7: Streaming: Overview, Fundamental Concepts, Walkthrough of Google Pub/Sub & Google DataFlow as example technologies\n        *   WEEK 8: Streaming: Kafka as another example of message queue technology & Spark Streaming\n        *   WEEK 9: Big Data ML: DataProc with ML - including Spark ML (Batch processing)\n        *   WEEK 10: Deep Learning with big data on cloud.\n        *   WEEK 11: Prep week for final project, summarizing key concepts, and also for Q&A and clarifications\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n13. **Game Theory**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Game Theory\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by introductory nature)\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction and General Principles\n        *   WEEK 2: Games with Simultaneous Moves I\n        *   WEEK 3: Games with Simultaneous Move II\n        *   WEEK 4: Games with Sequential Moves\n        *   WEEK 5: Combining Sequential and Simultaneous Moves and Mixed Strategies\n        *   WEEK 6: Evolutionary game Theory\n        *   WEEK 7: Matching Problem, Gale-Shapley Algorithm\n        *   WEEK 8: Voting, Cascades, and Arrow\u2019s Impossibility Theorem\n        *   WEEK 9: Cooperative Games, Shapley Values\n        *   WEEK 10: Fair Division, Bankruptcy Problems\n        *   WEEK 11: Auctions\n        *   WEEK 12: Network Effects\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n14. **Deep Learning**\n    *   **Level of Course:** Degree Level Course (Core Option II)\n    *   **Name of course:** Deep Learning\n    *   **Professor:** Prof. Mitesh M.Khapra\n    *   **Course ID:** BSCS3004\n    *   **Course Credits:** 4\n    *   **Course Type:** Core Option II\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** A brief history of deep learning and its success stories. Perceptrons, Sigmoid neurons and Multi-Layer Perceptrons (MLP) with specific emphasis on their representation power and algorithms used for training them (such as Perceptron Learning Algorithm and Backpropagation). Gradient Descent (GD) algorithm and its variants like Momentum based GD,AdaGrad, Adam etc Principal Component Analysis and its relation to modern Autoencoders. The bias variance tradeoff and regularisation techniques used in DNNs (such as L2 regularisation, noisy data augmentation, dropout, etc). Different activation functions and weight initialization strategies. Convolutional Neural Networks (CNNs) such as AlexNet, ZFNet, VGGNet, InceptionNet and ResNet. Recurrent Neural Network (RNNs) and their variants such as LSTMs and GRUs (in particular, understanding the vanishing/exploding gradient problem and how LSTMs overcome the vanishing gradient problem). Applications of CNN and RNN models for various computer vision and Natural Language Processing (NLP) problems.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: History of Deep Learning, McCulloch Pitts Neuron, Thresholding Logic, Perceptron Learning Algorithm and Convergence\n        *   WEEK 2: Multilayer Perceptrons (MLPs), Representation Power of MLPs, Sigmoid Neurons, Gradient Descent\n        *   WEEK 3: Feedforward Neural Networks, Representation Power of Feedforward Neural Networks, Backpropagation\n        *   WEEK 4: Gradient Descent(GD), Momentum Based GD, Nesterov Accelerated GD, Stochastic GD, Adagrad, AdaDelta,RMSProp, Adam,AdaMax,NAdam, learning rate schedulers\n        *   WEEK 5: Autoencoders and relation to PCA , Regularization in autoencoders, Denoising autoencoders, Sparse autoencoders, Contractive autoencoders\n        *   WEEK 6: Bias Variance Tradeoff, L2 regularization, Early stopping, Dataset augmentation, Parameter sharing and tying, Injecting noise at input, Ensemble methods, Dropout\n        *   WEEK 7: Greedy Layer Wise Pre-training, Better activation functions, Better weight initialization methods, Batch Normalization\n        *   WEEK 8: Learning Vectorial Representations Of Words, Convolutional Neural Networks, LeNet, AlexNet, ZF-Net, VGGNet, GoogLeNet, ResNet\n        *   WEEK 9: Visualizing Convolutional Neural Networks, Guided Backpropagation, Deep Dream, Deep Art, Fooling Convolutional Neural Networks\n        *   WEEK 10: Recurrent Neural Networks, Backpropagation Through Time (BPTT), Vanishing and Exploding Gradients, Truncated BPTT\n        *   WEEK 11: Gated Recurrent Units (GRUs), Long Short Term Memory (LSTM) Cells, Solving the vanishing gradient problem with LSTM\n        *   WEEK 12: Encoder Decoder Models, Attention Mechanism, Attention over images, Hierarchical Attention, Transformers.\n    *   **About the Instructors:** Mitesh M. Khapra is an Associate Professor in the Department of Computer Science and Engineering at IIT Madras and is affiliated with the Robert Bosch Centre for Data Science and AI. He is also a co-founder of One Fourth Labs and AI4Bharat. His research interests span Deep Learning, Multimodal Multilingual Processing, Natural Language Generation, Dialog systems, Question Answering and Indic Language Processing. He has prior experience as a Researcher at IBM Research India and holds a PhD and M.Tech from IIT Bombay. He is a recipient of several awards including the Google Faculty Research Award and the IITM Young Faculty Recognition Award.\n\n15. **Computational Biology**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Computational Biology\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** BSBT4001\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from the weekly topics - algorithmic and computational approaches to biological problems)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Why computational biology?\n        *   WEEK 2: Where in the Genome Does DNA Replication Begin? - Algorithmic warmup (frequent exact/inexact k-mers in a string).\n        *   WEEK 3: Which DNA Patterns Play the Role of Molecular Clocks? - Randomized Algorithms (randomized motif search, Gibbs sampling).\n        *   WEEK 4: How Do We Assemble Genomes? - Graph Algorithms (Eulerian paths, de Bruijn graphs).\n        *   WEEK 5: How Do We Compare Biological Sequences? - Dynamic Programming (edit distance, single/multiple sequence alignment).\n        *   WEEK 6: Which Animal Gave Us SARS? - Evolutionary Tree Reconstruction (distance-based phylogeny, neighbor-joining algorithm).\n        *   WEEK 7: How Did Yeast Become a Winemaker? - Clustering Algorithms (hard and soft k-means).\n        *   WEEK 8: How Do We Locate Disease-Causing Mutations? - Combinatorial Pattern Matching (suffix trees/arrays, Burrows-Wheeler transform).\n        *   WEEK 9: Why Have Biologists Still Not Developed an HIV Vaccine? - Hidden Markov Models (Viterbi and forward\u2013backward algorithms).\n        *   WEEK 10: Was T. rex Just a Big Chicken? - Computational Proteomics (peptide identification and spectral match).\n        *   WEEK 11: Which Motifs Are Hidden in a Biological Network? - Randomized Algorithms (colour coding for long paths in graphs).\n        *   WEEK 12: How Do We Distinguish Between the Flu and a Common Cold? - Support Vector Machines.\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n16. **Large Language Models**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Large Language Models\n    *   **Professor:** Prof. Mitesh M.Khapra\n    *   **Course ID:** BSCS5001\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** BSCS3004 - Deep Learning\n    *   **What you\u2019ll learn:** (Inferred from the weekly topics - in-depth understanding of transformers and large language models)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses by the same instructor)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Transformers: Introduction to transformers - Self-attention - cross- attention-Masked attention-Positional encoding\n        *   WEEK 2: A deep dive into number of parameters, computational complexity and FLOPs- Introduction to language modeling\n        *   WEEK 3: Causal Language Modeling: What is a language model?- Generative Pretrained Transformers (GPT) - Training and inference\n        *   WEEK 4: Masked Language Modeling : Bidirectional Encoder Representations of Transformers (BERT) - Fine-tuning - A deep dive into tokenization: BPE, SentencePiece, wordpiece\n        *   WEEK 5: Bigger Picture: T5, A deep dive into text-to-text (genesis of prompting), taxonomy of models, road ahead\n        *   WEEK 6: Data: Datasets, Pipelines, effectiveness of clean data, Architecture: Types of attention, positional encoding (PE) techniques, scaling techniques\n        *   WEEK 7: Training: Revisiting optimizers, LION vs Adam, Loss functions, Learning schedules, Gradient Clipping, typical failures during training\n        *   WEEK 8: Fine Tuning: Prompt Tuning,Multi-task Fine-tuning,Parametric Efficient Fine-Tuning, Instruction fine-tuning datasets\n        *   WEEK 9: Benchmarks: MMLU, BigBench, HELM,OpenLLM, Evaluation Frameworks\n        *   WEEK 10: Training Large Models: Mixed precision training,Activation checkpointing, 3D parallelism, ZERO, Bloom as a case study\n        *   WEEK 11: Scaling Laws: Chinchilla,Gopher, Palm v2\n        *   WEEK 12: Recent advances\n    *   **About the Instructors:** Prof. Mitesh M.Khapra is an Associate Professor in the Department of Computer Science and Engineering at IIT Madras and is affiliated with the Robert Bosch Centre for Data Science and AI. (Detailed biographical information as in the Deep Learning course).\n\n17. **Probabilistic Deep Generative Modelling**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Probabilistic Deep Generative Modelling\n    *   **Professor:** Prathosh A P\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by introductory nature)\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - generative models in deep learning)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Probabilistic Deep Generative Modelling\n        *   WEEK 2: Generative Modelling via variational Divergence Minimization\n        *   WEEK 3: Generative Adversarial Networks: Part 1 (Introduction and Formulation)\n        *   WEEK 4: Generative Adversarial Networks: Part 2 (WGANs and Applications)\n        *   WEEK 5: Generative Modelling via Variational Auto Encoding\n        *   WEEK 6: Variational Auto Encoders: Improvisations and VQVAE\n        *   WEEK 7: Denoising Diffusion Probabilistic Models (DDPMs) - Formulation\n        *   WEEK 8: Diffusion Models: Multiple forms and Implementation\n        *   WEEK 9: Conditional Diffusion Models and Score-based models\n        *   WEEK 10: Auto-Regressive Models and Large Language Models Introduction\n        *   WEEK 11: LLMs: Models, Sampling, Inference and Quantization Methods\n        *   WEEK 12: LLMs \u2013 Reinforcement Learning based Alignment Methods (PPO, DPO)\n    *   **About the Instructors:** Prathosh A P is an Assistant Professor in the Division of EECS at IISc Bangalore.\n\n18. **Artificial Intelligence**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Artificial Intelligence\n    *   **Professor:** Deepak Khemani (based on the prescribed book)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by \"A First Course\")\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - fundamental concepts and algorithms in AI)\n    *   **Course structure & Assessments:** 11 weeks of coursework (plus one inferred), weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12 (inferred)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction and philosophy. The Turing Test. The Winograd Schema Challenge. Placing search in the landscape of AI.\n        *   WEEK 2: Search spaces. Examples. State space search. Depth First, Breadth First, Iterative Deepening. Analysis.\n        *   WEEK 3: Heuristic search. Heuristic functions. Solution space search. Escaping local optima. Stochastic local search.\n        *   WEEK 4: Population based methods. Genetic Algorithms, emergent systems, Ant Colony Optimization.\n        *   WEEK 5: Finding optimal paths. Algorithm A*. Admissibility of A*.\n        *   WEEK 6: The monotone condition. Space saving versions of A*. Sequence alignment.\n        *   WEEK 7: Game playing. Board games. Algorithms Minimax, Alpha-Beta, and SSS*.\n        *   WEEK 8: Automated domain independent planning. Goal Stack Planning, Partial Order Planning.\n        *   WEEK 9: Problem decomposition with goal trees. Algorithm AO*.\n        *   WEEK 10: Pattern directed inference systems. Forward chaining inference engine. The Rete algorithm.\n        *   WEEK 11: Constraint processing. Algorithm Backtracking. Arc consistency. Combining search and reasoning. Waltz algorithm. Model based diagnosis.\n        *   WEEK 12: (Not explicitly stated but typically a revision or further topic)\n    *   **About the Instructors:** (Deepak Khemani is the author of the prescribed book, but his affiliation to IIT Madras for this specific course is not stated in this excerpt).\n\n19. **Advanced Algorithms**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Advanced Algorithms\n    *   **Professor:** Neeldhara Misra\n    *   **Course ID:** BSCS4021\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** To introduce advanced ideas in design of algorithms. To study the performance guarantees of algorithms. To introduce methods for coping with NP-hard problems.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Greedy Algorithms: Storing Files on Tape; Scheduling Classes; Stable Matchings\n        *   WEEK 2: Matroids: A Generic Optimization Problem, Motivating the Definition, Examples of Matroids, Scheduling with Deadlines\n        *   WEEK 3: Dynamic Programming: Longest Increasing Subsequence, Edit Distance, Subset Sum, Optimal BSTs\n        *   WEEK 4: Maximum Flows: Flows, Cuts, Maxflow-Mincut, Augmenting Paths, Bipartite Matchings, Other Settings\n        *   WEEK 5: Applications of Flows: Exam Scheduling, Baseball Elimination, Project Selection\n        *   WEEK 6: NP-hardness: P, NP, NP-hardness, NP-completeness, Reductions and SAT, 3SAT, Maximum Independent Set, Graph Coloring, Subset Sum\n        *   WEEK 7: Approximation Algorithms: Introduction to Approximation Frameworks, Vertex Cover via Maximal Matchings, Vertex Cover via LP rounding, TSP, Set Cover\n        *   WEEK 8: Randomized Algorithms \u2013 Monte Carlo v. Las Vegas, Min-Cut Algorithm, MAX SAT via the Probabilistic Methods, 2SAT via Markov Chains, Primality Testing\n        *   WEEK 9: Exact Algorithms \u2013 Branch and Bound, An Inclusion-Exclusion approach to Hamiltonian Path, Dynamic Programming for TSP, Local Search\n        *   WEEK 10: Parameterized Algorithms \u2013 Closest String, Iterative Compression for FVS, Randomized Algorithm for k-Path, DP over subsets - Set Cover\n        *   WEEK 11: Kernelization \u2013 Vertex Cover, Matrix Rigidity, Feedback Arc Set on Tournaments, Max Sat, Edge Clique Cover\n        *   WEEK 12: Practical Approaches to Coping with Hardness \u2013 SAT Solvers, SAT reductions, LP solvers, LP reductions\n    *   **About the Instructors:** Neeldhara Misra is an Assistant Professor of Computer Science and Engineering at the Indian Institute of Technology, Gandhinagar. Her research interests involve the design and analysis of efficient algorithms for \u201chard\u201d problems, particularly parameterized algorithms.\n\n20. **Forensic Accounting and Fraud Analytics**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Forensic Accounting and Fraud Analytics\n    *   **Professor:** Dr. Arun Kumar G\n    *   **Course ID:** BSGN3002\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - application of accounting and data analytics to detect fraud)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: INTRODUCTION TO ACCOUNTING AND FINANCE: Financial Statements | Uses relevance of financial statements | Decision making in the financial arena | Need for finance and accounting in a business world\n        *   WEEK 2: FRAUD VULNERABILITIES AND FINANCE: Types of fraud | Why do they occur | Where do they occur | Detecting red flags\n        *   WEEK 3: FORENSIC ACCOUNTING - 1: Intro to Forensic Accounting | Source of assignments and referrals for a forensic accountant | Role of the forensic accountant as an expert - identify any conflicts\n        *   WEEK 4: FORENSIC ACCOUNTING - 2: Scope of forensic accounting | Process of forensic accounting - Analysis\n        *   WEEK 5: BENFORD LAW AND IMPLEMENTATION: Benford Law | Using Benford Law in Excel to detect audit fraud\n        *   WEEK 6: AGING ANALYSIS, PARETO AND OUTLIERS: Detecting fraud using Aging Analysis in Excel | Creating a Pareto Chart | Outlier identification\n        *   WEEK 7: FINANCIAL TRANSACTION LIFECYCLE: Transaction Lifecycle | Where is AI/ML used in the present world?\n        *   WEEK 8: ENTITY RESOLUTION: What is an entity in a transaction? | Entity resolution\n        *   WEEK 9: ANOMALY DETECTION - 1: Supervised Anomaly Detection\n        *   WEEK 10: ANOMALY DETECTION - 2: Unsupervised Anomaly Detection\n        *   WEEK 11: ANOMALY DETECTION - 3: Time Based Anomaly Detection\n        *   WEEK 12: Model Explainability | Financial Data Visualization using Tableau\n    *   **About the Instructors:** (Biographical information for Dr. Arun Kumar G is not provided in this excerpt).\n\n21. **Deep Learning Practice**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Deep Learning Practice\n    *   **Professor:** Prof. Mitesh M.Khapra, Prof. S. Umesh, Dr. Kaushik Mitra\n    *   **Course ID:** BSDA5013\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** BSCS3004 - Deep Learning\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - practical application of deep learning techniques to various domains)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses by the same instructors)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Modern NLP and HF\n        *   WEEK 2: Tokenization\n        *   WEEK 3: Fine-tuning models for downstream tasks\n        *   WEEK 4: Continual Pre-training and Instruction Tuning\n        *   WEEK 5: Spoken Language Identification\n        *   WEEK 6: Speaker Diarisation (identifying speakers and when they are spoken in a conversation)\n        *   WEEK 7: Speech to Text and Text to Speech synthesis\n        *   WEEK 8: Wake word detection like \"Hey Google\" or \"Alexa\" with personalization\n        *   WEEK 9: Image Classification\n        *   WEEK 10: Object detection\n        *   WEEK 11: Image based depth estimation\n        *   WEEK 12: Image super-resolution\n    *   **About the Instructors:** (Biographical information for Prof. Mitesh M.Khapra is detailed in the Deep Learning course. Biographical information for Prof. S. Umesh and Dr. Kaushik Mitra is not provided in this excerpt).\n\n22. **Corporate Finance**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Corporate Finance\n    *   **Professor:** Dr. Bikramaditya Datta\n    *   **Course ID:** BSMS3034\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - fundamental concepts in corporate finance)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Finance\n        *   WEEK 2: Present Value, Annuities and Perpetuities\n        *   WEEK 3: Capital Budgeting Rules, Time Varying Rates of Return, Uncertainty, Default and Risk\n        *   WEEK 4: Investment: Risk and Rewards, Choice Under Uncertainty\n        *   WEEK 5: Portfolio Theory\n        *   WEEK 6: Capital Asset Pricing Theory\n        *   WEEK 7: Other Pricing Models: Factor Models, Arbitrage Pricing Theory\n        *   WEEK 8: Market Efficiency: Market Imperfections, and Applications to Capital Budgeting Rules\n        *   WEEK 9: Introduction to Derivative Securities and Basic Options Theory I\n        *   WEEK 10: Introduction to Derivative Securities and Basic Options Theory II\n        *   WEEK 11: Foreign Exchange Markets and International Financial System\n        *   WEEK 12: Financial Crises\n    *   **About the Instructors:** Dr. Bikramaditya Datta is an Assistant Professor in the Department of Economic Sciences at IIT Kanpur.\n\n23. **Operating System**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Operating System\n    *   **Professor:** Chester Rebeiro\n    *   **Course ID:** BSCS4022\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** BSCS3031 - Computer Systems Design\n    *   **What you\u2019ll learn:** To learn about the internal organisation of the computer. To learn about the architecture of a computer\u2019s CPU (This information is from the Computer Systems Design course, likely a typo here).\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction and system organization\n        *   WEEK 2: Booting /Memory management\n        *   WEEK 3: Processes and system calls\n        *   WEEK 4: Child process, first process, fork, exit and wait system calls\n        *   WEEK 5: Exec system call, Executables, ELF format\n        *   WEEK 6: Interrupts and interrupts handling\n        *   WEEK 7: Scheduling\n        *   WEEK 8: Synchronization\n        *   WEEK 9: Deadlocks and Threads\n        *   WEEK 10: File system\n        *   WEEK 11: Security: OS security and Side-Channel Attacks\n        *   WEEK 12: Security: TEEs and Buffer Overflow\n    *   **About the Instructors:** Chester Rebeiro is currently Associate Professor at IIT Madras. He completed his PhD from IIT Kharagpur and a post-doc from Columbia University. His research interests are hardware security, applied cryptography, side channel analysis, and operating system security.\n\n24. **Software Engineering**\n    *   **Level of Course:** Degree Level Course (Core Option I)\n    *   **Name of course:** Software Engineering\n    *   **Professor:** Dr. Sridhar Iyer, Dr. Prajish Prasad\n    *   **Course ID:** BSCS3001\n    *   **Course Credits:** 4\n    *   **Course Type:** Core Option I\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Not explicitly stated in this excerpt, inferred from weekly topics - principles and practices of software development)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Deconstructing the software development process\n        *   WEEK 2: Identify different types of software requirements (functional, non-functional)\n        *   WEEK 3: Software Conceptual Design\n        *   WEEK 4: Software Usability\n        *   WEEK 5: Software Design - Modeling and Architecture\n        *   WEEK 6: Software Design - Quality and Evaluation\n        *   WEEK 7: Software Development - Program Comprehension\n        *   WEEK 8: Software Development - Program Debugging\n        *   WEEK 9: Software - Code Reviewing and Documentation\n        *   WEEK 10: Software Testing\n        *   WEEK 11: Software Deployment and Monitoring\n        *   WEEK 12: Conclusion and other Aspects: Communication, Productivity and Organizations\n    *   **About the Instructors:** (Biographical information for Dr. Sridhar Iyer and Dr. Prajish Prasad is not provided in this excerpt).\n\n25. **Speech Processing**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** Speech Processing (inferred from content)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (implied by the review of basic signals and systems)\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - techniques for analyzing and processing speech signals)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Review of Signals and Systems, Continuous time signals and transforms Discrete time signals, Discrete Fourier transform, Autocorrelation and Cross-Correlation\n        *   WEEK 2: Acoustic Feature Analysis of Speech Signals I, II Gaussian mixture models (GMM), universal background model (UBM-GMM), singular value decomposition (SVD)\n        *   WEEK 3: Hidden Markov model (HMM), Examples of HMM based approach for ASR, TTS, speaker diarization Information bottleneck (IB) based clustering for diarization\n        *   WEEK 4: Introduction and History of ASR and TTS Components of ASR: Acoustic Modelling, Punctuation Model (Lexicon) and language modelling (N-Gram Language models)\n        *   WEEK 5: HMMs for Acoustic Modelling - Monophone, Triphone Speech Synthesis: unit selection, statistical parametric synthesis (HTS)\n        *   WEEK 6: Neural networks for building speech technologies NN for Acoustic Modelling - Hybrid modelling- Hybrid-NN: DNN,CNN,TDNN\n        *   WEEK 7: End-to-End Approaches I: CTC, Encoder-decoder Architecture E2E with RNN\n        *   WEEK 8: Applications to ASR and TTS End-to-End Approaches II\n        *   WEEK 9: Encoder-decoder Architecture E2E with transformers for ASR and TTS Interesting Problems\n        *   WEEK 10: Speaker recognition/verification: with ivector, xvector Speaker diarization: using x-vector\n        *   WEEK 11: Speaker adaptation: (revisit i, x vectors) and introduce s-vectors. Code Switched Speech recognition; Speech Translation\n        *   WEEK 12: Singing voice synthesis; voice conversion; generic voice synthesis\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n26. **Data Visualization Design**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Data Visualization Design\n    *   **Professor:** Prof. Venkat\n    *   **Course ID:** BSCS4001\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** To provide students with the foundations necessary for understanding and extending the current state of the art in data visualization, to gain an understanding of the key techniques and theory used in visualization, including data models, graphical perception and techniques for visual encoding and interaction, to plan for data-based storytelling through charts, maps, and diagrams, to use visualization tools to transform quantitative information to visual representation, and to gain practical experience building and evaluating visualizations.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Information visualization overview, historical perspective\n        *   WEEK 2: Vision, perception and cognition principles of information visualization\n        *   WEEK 3: Data principles and models\n        *   WEEK 4: Analysis and Insights\n        *   WEEK 5: Geo-visualization\n        *   WEEK 6: Map Abstraction\n        *   WEEK 7: Visual encoding of data\n        *   WEEK 8: Visualization design\n        *   WEEK 9: Data Stories\n        *   WEEK 10: Project presentations, Wrap up and course summary\n        *   WEEK 11: (Not explicitly stated)\n        *   WEEK 12: (Not explicitly stated)\n    *   **About the Instructors:** (Biographical information for Prof. Venkat is not provided in this excerpt).\n\n27. **Computer Vision**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Computer Vision\n    *   **Professor:** Prof. Vineeth N B\n    *   **Course ID:** BSCS5003\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - fundamental techniques in computer vision and deep learning based approaches)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12 (inferred from other courses)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction and Overview: Course Overview and Motivation; Introduction to Image Formation, Capture and Representation; Linear Filtering, Correlation, Convolution\n        *   WEEK 2: Visual Features and Representations: Edge, Blobs, Corner Detection; Scale Space and Scale Selection; SIFT, SURF; HoG,LBP, etc.\n        *   WEEK 3: Visual Matching: Bag-of-words, VLAD; RANSAC, Hough transform; Pyramid Matching; Optical Flow\n        *   WEEK 4: Deep Learning Review: Review of Deep Learning, Multi-layer Perceptrons, Backpropagation\n        *   WEEK 5: Convolutional Neural Networks (CNNs): Introduction to CNNs; Evolution of CNN Architectures: AlexNet, ZFNet, VGG, InceptionNets, ResNets, DenseNets\n        *   WEEK 6: Visualization and Understanding CNNs: Visualization of Kernels; Backprop-to-image/Deconvolution Methods; Deep Dream, Hallucination, Neural Style Transfer; CAM, Grad-CAM, Grad-CAM++; Recent Methods (IG, Segment-IG, SmoothGrad)\n        *   WEEK 7: CNNs for Recognition, Verification, Detection, Segmentation: CNNs for Recognition and Verification (Siamese Networks, Triplet Loss, Contrastive Loss, Ranking Loss); CNNs for Detection: Background of Object Detection, R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD, RetinaNet; CNNs for Segmentation: FCN, SegNet, U-Net, Mask-RCNN\n        *   WEEK 8: Recurrent Neural Networks (RNNs): Review of RNNs; CNN + RNN Models for Video Understanding: Spatio-temporal Models, Action/Activity Recognition\n        *   WEEK 9: Attention Models: Introduction to Attention Models in Vision; Vision and Language: Image Captioning, Visual QA, Visual Dialog; Spatial Transformers; Transformer Networks\n        *   WEEK 10: Deep Generative Models: Review of (Popular) Deep Generative Models: GANs, VAEs; Other Generative Models: PixelRNNs, NADE, Normalizing Flows, etc\n        *   WEEK 11: Variants and Applications of Generative Models in Vision: Applications: Image Editing, Inpainting, Superresolution, 3D Object Generation, Security; Variants: CycleGANs, Progressive GANs, StackGANs, Pix2Pix, etc\n        *   WEEK 12: Recent Trends: Zero-shot, One-shot, Few-shot Learning; Self-supervised Learning; Reinforcement Learning in Vision; Other Recent Topics and Applications\n    *   **About the Instructors:** Prof. Vineeth N B's biographical information is not provided in this excerpt.\n\n28. **Statistical Methods for Business Analytics**\n    *   **Level of Course:** Degree Level Course (Data Science)\n    *   **Name of course:** Statistical Methods for Business Analytics\n    *   **Professor:** Prof. Rahul R Marathe\n    *   **Course ID:** BSMS2002\n    *   **Course Credits:** 4\n    *   **Course Type:** Data Science\n    *   **Pre-requisites:** BSMS2001 - Business Data Management\n    *   **What you\u2019ll learn:** At the end of the this course, the students will be able to apply various statistical techniques to solve various business problems. Extrapolate using various techniques and with statistical robustness. Build data-centric business models.\n    *   **Course structure & Assessments:** 8 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 8\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Data dashboarding Insights from data summary\n        *   WEEK 2: Can summarizing the data provide insights?\n        *   WEEK 3: Do people in different cities prefer different brand?\n        *   WEEK 4: Predicting the stock returns \u2013 Regression basics\n        *   WEEK 5: How do you pay a professor? \u2013 Regression diagnostics - Path variables\n        *   WEEK 6: Can I cure cancer? \u2013 Logistic Regression - Connection with classification problem\n        *   WEEK 7: What is the impact of repeatedly watching the same ad? Repeated measures ANOVA\n        *   WEEK 8: When the data has a time axis: Time series modeling\n    *   **About the Instructors:** (Biographical information for Prof. Rahul R Marathe is not provided in this excerpt).\n\n29. **Strategies for Professional Growth**\n    *   **Level of Course:** Degree Level Course (Mandatory)\n    *   **Name of course:** Strategies for Professional Growth\n    *   **Professor:** Prof. Sivakumar M S, Lt Col Jayakumar, Prasanna G, Shiva Subramaniam, Kartic Vaidyanathan, Senthil A V, Prathap Haridoss\n    *   **Course ID:** BSGN3001\n    *   **Course Credits:** 4\n    *   **Course Type:** Mandatory\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - various soft skills and professional development aspects)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Teamwork and Getting Along\n        *   WEEK 2: Communication and Listening Skills\n        *   WEEK 3: Cultivating a Growth Mindset\n        *   WEEK 4: Leadership Lessons\n        *   WEEK 5: Emotional Intelligence and Conflict Management\n        *   WEEK 6: Systems Thinking\n        *   WEEK 7: Engineering Sense\n        *   WEEK 8: Creativity and Thinking Skills\n        *   WEEK 9: Cross-cultural Understanding and Personal Grooming\n        *   WEEK 10: Fiscal and Economic Sense\n        *   WEEK 11: Presentation Skills\n        *   WEEK 12: Personal and Professional Development\n    *   **About the Instructors:** (Biographical information for these instructors was provided in detail in the previous turn of our conversation).\n\n30. **Managerial Economics**\n    *   **Level of Course:** Degree Level Course\n    *   **Name of course:** Managerial Economics\n    *   **Professor:** Vimal Kumar\n    *   **Course ID:** BSMS3033\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - application of microeconomic principles to business decision-making)\n    *   **Course structure & Assessments:** For details of standard course structure and assessments, visit Academics page.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction\n        *   WEEK 2: Demand, Supply, and markets\n        *   WEEK 3: Elasticity and Empirical Methods for Demand Analysis\n        *   WEEK 4: Consumer Behavior\n        *   WEEK 5: Technology, Production, and Costs\n        *   WEEK 6: Perfectly Competitive Market\n        *   WEEK 7: Monopoly\n        *   WEEK 8: Monopsony and Monopolistic Competition\n        *   WEEK 9: Decisions under Risk and Uncertainty\n        *   WEEK 10: Asymmetric Information\n        *   WEEK 11: Government and Businesses\n        *   WEEK 12: Platform Businesses\n    *   **About the Instructors:** Vimal Kumar is an Associate Professor in the Department of Economic Science at IIT Kanpur.\n\n31. **Reinforcement Learning**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Reinforcement Learning\n    *   **Professor:** Prof. Balaraman Ravindran\n    *   **Course ID:** BSCS4002\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** BSCS3004 - Deep Learning\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - fundamentals and advanced topics in reinforcement learning)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Review of ML fundamentals \u2013 Classification, Regression. Review of probability theory and optimization concepts.\n        *   WEEK 2: RL Framework; Supervised learning vs. RL; Explore-Exploit Dilemma; Examples.\n        *   WEEK 3: MAB: Definition, Uses, Algorithms, Contextual Bandits, Transition to full RL, Intro to full RL problem\n        *   WEEK 4: Intro to MDPs: Definitions  , Returns, Value function, Q-function.\n        *   WEEK 5: Bellman Equation, DP, Value Iteration, Policy Iteration, Generalized Policy Iteration.\n        *   WEEK 6: Evaluation and Control: TD learning, SARSA, Q-learning, Monte Carlo, TD Lambda, Eligibility Traces.\n        *   WEEK 7: Maximization-Bias & Representations: Double Q learning, Tabular learning vs. Parameterized, Q-learning with NNs\n        *   WEEK 8: Function approximation: Semi-gradient methods, SGD, DQNs, Replay Buffer.\n        *   WEEK 9: Policy Gradients: Introduction, Motivation, REINFORCE, PG theorem, Introduction to AC methods\n        *   WEEK 10: Actor-Critic Methods, Baselines, Advantage AC, A3C Advanced Value-Based Methods: Double DQN, Prioritized Experience Replay, Dueling Architectures, Expected SARSA.\n        *   WEEK 11: Advanced PG/A-C methods: Deterministic PG and DDPG, Soft Actor-Critic (SAC) HRL: Introduction to hierarchies, types of optimality, SMDPs, Options, HRL algorithms POMDPS: Intro, Definitions, Belief states, Solution Methods; History-based methods, LSTMS, Q-MDPs, Direct Solutions, PSR.\n        *   WEEK 12: Model-Based RL: Introduction, Motivation, Connections to Planning, Types of MBRL, Benefits, RL with a Learnt Model, Dyna-style models, Latent variable models, Examples, Implicit MBRL. Case study on design of RL solution for real-world problems.\n    *   **About the Instructors:** (Biographical information for Prof. Balaraman Ravindran is not provided in this excerpt).\n\n32. **Programming in C**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Programming in C\n    *   **Professor:** Prof. Nitin Chandrachoodan\n    *   **Course ID:** BSCS3005\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - fundamental concepts of programming in the C language)\n    *   **Course structure & Assessments:** 8 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 8\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Write, compile, and run programs in C in a Linux environment; debugging tools\n        *   WEEK 2: Variables, built-in datatypes, operators; Control flow - conditionals, loops\n        *   WEEK 3: Modularity and functions; variable scope\n        *   WEEK 4: Input/Output; Files\n        *   WEEK 5: Pointers, memory, arrays, strings\n        *   WEEK 6: Multi-dimensional arrays, dynamic memory allocation; issues - memory leaks, management\n        *   WEEK 7: Standard library and common extensions (math, time, etc.)\n        *   WEEK 8: Implementation concepts: compilation and execution process; heap/stack; runtime and OS interface\n    *   **About the Instructors:** (Biographical information for Prof. Nitin Chandrachoodan is available in other course descriptions, but not repeated here for brevity).\n\n33. **Sequential Decision Making**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Sequential Decision Making\n    *   **Professor:** Arun Rajkumar\n    *   **Course ID:** BSDA5007\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - online learning and multi-armed bandit problems, introduction to reinforcement learning)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Online Learning, Halving algorithm\n        *   WEEK 2: Online Machine Learning; Perceptron and Winnow\n        *   WEEK 3: Intro to Regret; Online learning with expert advice - Hedge algorithm\n        *   WEEK 4: Online linear optimization\n        *   WEEK 5: Online convex optimization; Online learning summary\n        *   WEEK 6: Introduction to Multi armed Bandits - EXP3\n        *   WEEK 7: Contextual MAB - EXP4\n        *   WEEK 8: Stochastic MAB, Epsilon Greedy, Explore then commit\n        *   WEEK 9: Stochastic MAB, UCB, Thompson Sampling\n        *   WEEK 10: Stochastic MAB - Linear Bandits - LinUCB algorithm; MAB summary\n        *   WEEK 11: Introduction to Reinforcement Learning - Markov Decision Process\n        *   WEEK 12: Q-learning\n    *   **About the Instructors:** Arun Rajkumar is an Assistant Professor in the Department of Data Science and AI at IIT Madras. (Detailed biographical information as in the Algorithms for Data Science course).\n\n34. **Industry 4.0**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Industry 4.0\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - concepts and technologies related to Industry 4.0)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Industry 4.0 \u2013 Evolution and history\n        *   WEEK 2: Pillars of Industry 4.0\n        *   WEEK 3: Industry 4.0 \u2013 India context\n        *   WEEK 4: Supplier selection as a classification problem\n        *   WEEK 5: Manufacturing 4.0\n        *   WEEK 6: Prognosis\n        *   WEEK 7: Quality 4.0\n        *   WEEK 8: Inventory Optimization\n        *   WEEK 9: Dynamic Pricing\n        *   WEEK 10: Logistics 4.0\n        *   WEEK 11: Future of Manufacturing Business Focus on new paradigm\n        *   WEEK 12: Next decade of Industry 4.0\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n35. **Statistical Computing**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Statistical Computing\n    *   **Professor:** Dootika Vats\n    *   **Course ID:** BSMA3014\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** To introduce computational methods involved in statistical estimation and learning problems.\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to R, Introduction to Monte Carlo, Pseudorandom Number Generation, Sampling Discrete Random Variables: Inverse Transform Method\n        *   WEEK 2: Discrete: Accept-Reject Algorithm, Composition Method, Sampling Continuous Random Variables: Inverse Transform Method\n        *   WEEK 3: Continuous: Accept-reject Algorithm with examples, Box-Muller method\n        *   WEEK 4: Continuous: Ratio-of-Uniforms method, examples and code, miscellaneous methods in sampling, Sampling from multivariate distritbutions\n        *   WEEK 5: Simple Importance Sampling: Examples, bias, variance, consistency, Optimal proposals,\n        *   WEEK 6: Weighted importance sampling: Examples, Review of likelihood functions, MLE examples\n        *   WEEK 7: Linear regression as MLE, Penalized regression, No-closed form MLEs, Review of Taylor Series Approximations\n        *   WEEK 8: Newton's optimization algorithm: examples and code, Gradient Descent algorithm, applications to logistic regression with code\n        *   WEEK 9: MM algorithm, application to Bridge Regression, EM algorithm, Introduction to Gaussian Mixture Model\n        *   WEEK 10: EM algorithm for GMM, Cross-validation with examples\n        *   WEEK 11: Bootstrapping: examples and code. Application to bridge regression, stochastic gradient descent\n        *   WEEK 12: Applications of SGD with code. Simulated annealing: examples, codes, and challenges\n    *   **About the Instructors:** (Biographical information for Dootika Vats is not provided in this excerpt).\n\n36. **Computer Systems Design**\n    *   **Level of Course:** Degree Level Course (Elective)\n    *   **Name of course:** Computer Systems Design\n    *   **Professor:** Ayon Chakraborty\n    *   **Course ID:** BSCS3031\n    *   **Course Credits:** 4\n    *   **Course Type:** Elective\n    *   **Pre-requisites:** None\n    *   **What you\u2019ll learn:** To learn about the internal organisation of the computer. To learn about the architecture of a computer\u2019s CPU.\n    *   **Course structure & Assessments:** 8 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam.\n    *   **Number of weeks:** 12 (inferred from weekly topics)\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Course Overview, Building Blocks of Computer Systems\n        *   WEEK 2: Foundation of Logical Circuits, Introduction to Boolean Algebra\n        *   WEEK 3: Canonical Forms (SOP & POS), Universal Gates and Timing Diagrams\n        *   WEEK 4: N- bit Comparator, Multiplexer, Encoder and Decoder\n        *   WEEK 5: Adder and PLA, Boolean Logic Simplification, K-maps\n        *   WEEK 6: Introduction to Circuit verse, 7 Segment LED Display\n        *   WEEK 7: Introduction to Sequential Circuits\n        *   WEEK 8: Registers, Counters\n        *   WEEK 9: Sequential logic design, FSM Design\n        *   WEEK 10: Instruction Set architecture\n        *   WEEK 11: ALU Design\n        *   WEEK 12: CPU Design\n    *   **About the Instructors:** (Biographical information for Ayon Chakraborty is not provided in this excerpt).\n\n37. **(Course Name Not Explicitly Stated - Advanced Object Oriented Programming)**\n    *   **Level of Course:** Degree Level Course (based on context)\n    *   **Name of course:** (Advanced Object Oriented Programming - inferred from content)\n    *   **Professor:** (Not explicitly stated in this excerpt)\n    *   **Course ID:** (Not explicitly stated in this excerpt)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** (Not explicitly stated in this excerpt)\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - advanced concepts in object-oriented programming)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam (standard structure inferred).\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Basic Object Oriented Programming: Class Hierarchy\n        *   WEEK 2: Basic Object Oriented Programming: Inheritance, Overriding\n        *   WEEK 3: Basic Object Oriented Programming: Polymorphism\n        *   WEEK 4: Basic Object Oriented Programming: Abstract Classes\n        *   WEEK 5: Collections. Iterators.\n        *   WEEK 6: Generics. Callbacks.\n        *   WEEK 7: Cloning. I/O serializations. Packages\n        *   WEEK 8: Cloning. I/O serializations. Packages (Continued)\n        *   WEEK 9: Exception handling\n        *   WEEK 10: Concurrent programming\n        *   WEEK 11: Concurrent programming (Continued)\n        *   WEEK 12: Concurrent programming (Continued)\n    *   **About the Instructors:** (Not explicitly stated in this excerpt)\n\n38. **(Course Name Not Explicitly Stated - Design Thinking for Data-Driven App Development)**\n    *   **Level of Course:** Degree Level Course (based on context, BSMS4002 Course ID mentioned under 'Other courses by the same instructor')\n    *   **Name of course:** (Design Thinking for Data-Driven App Development - inferred from content and instructor's other courses)\n    *   **Professor:** Prof. Sivakumar M S, Lt Col Jayakumar, Prasanna G, Shiva Subramaniam, Kartic Vaidyanathan, Senthil A V, Prathap Haridoss (same instructors as Strategies for Professional Growth)\n    *   **Course ID:** BSMS4002 (inferred)\n    *   **Course Credits:** (Not explicitly stated in this excerpt)\n    *   **Course Type:** (Not explicitly stated in this excerpt)\n    *   **Pre-requisites:** None (inferred)\n    *   **What you\u2019ll learn:** (Inferred from weekly topics - application of design thinking principles to app development)\n    *   **Course structure & Assessments:** 12 weeks of coursework, weekly online assignments, 2 in-person invigilated quizzes, 1 in-person invigilated end term exam (standard structure inferred).\n    *   **Number of weeks:** 12\n    *   **(LIST)Week#, Title:**\n        *   WEEK 1: Introduction to Design Thinking \u2013 Course outline and projects, Intro to the Design of Everyday Things, Intro to Design Thinking in software apps, Project management\n        *   WEEK 2: Empathize \u2013 P1 \u2013 Persona Creation, Customer Journey Mapping, Design Paradox, Demo on a real problem\n        *   WEEK 3: Empathize \u2013 P1 \u2013 List of problems, How Might We questions, Demo on a real problem\n        *   WEEK 4: Analyze \u2013 P1 \u2013 Multi-Why, Conflict of Interest, Demo on a real problem\n        *   WEEK 5: Solve \u2013 P1 \u2013 Silent brainstorming, Inventive Principles, Concept creation, Demo on a real problem\n        *   WEEK 6: Test \u2013 P1, Empathize \u2013 P2 Assumptions, Features, Field trials, Basics of Digital Marketing\n        *   WEEK 7: Website Development, User Experience Design, Prototypes\n        *   WEEK 8: Analyze \u2013 P2\n        *   WEEK 9: Solve \u2013 P2\n        *   WEEK 10: Test \u2013 P2, Empathize \u2013 P3 \u2013 Obtaining insights/ feedback from the customers or target users\n        *   WEEK 11: Analyze \u2013 P3\n        *   WEEK 12: Test \u2013 P3, Launch of the App\n    *   **About the Instructors:** Prof. Sivakumar M S, Lt Col Jayakumar, Prasanna G, Shiva Subramaniam, Kartic Vaidyanathan, Senthil A V, Prathap Haridoss (Biographical information as provided earlier).", "tags": ["degree", "level", "courses"], "source": "IITM BS Website"}
